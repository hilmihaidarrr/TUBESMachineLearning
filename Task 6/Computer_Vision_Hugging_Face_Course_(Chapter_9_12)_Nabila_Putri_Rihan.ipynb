{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 9: Model Optimization for Deployment\n",
        "\n",
        "### 1. Introduction to Model Optimization for Deployment\n",
        "##### Penjelasan:\n",
        "###### Model optimization bertujuan untuk meningkatkan efisiensi model machine learning dengan:\n",
        "###### - Mengurangi ukuran model untuk menghemat memori penyimpanan.\n",
        "###### - Meningkatkan kecepatan inferensi sehingga cocok untuk aplikasi real-time.\n",
        "###### - Mengurangi konsumsi daya, terutama pada perangkat edge seperti smartphone atau perangkat IoT.\n",
        "###### - Memastikan model tetap memberikan hasil yang akurat meskipun sudah dioptimasi.\n",
        "###### Proses ini menjadi sangat penting untuk penerapan di dunia nyata, terutama pada perangkat dengan keterbatasan sumber daya."
      ],
      "metadata": {
        "id": "To0J4v1g2Xr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch.nn.utils import prune\n",
        "\n",
        "# Menggunakan model pretrained ResNet18 sebagai contoh\n",
        "model = models.resnet18(pretrained=True)\n",
        "print(\"[INFO] Model awal sebelum optimasi:\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hvW6tqv2Waz",
        "outputId": "c2534f32-99cd-4ed9-d124-a795ff49d88c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Model awal sebelum optimasi:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Model Deployment Considerations\n",
        "### Penjelasan:\n",
        "#### Beberapa faktor yang harus dipertimbangkan saat melakukan deployment model adalah:\n",
        "###### - **Kecepatan Inferensi**: Model harus memberikan hasil prediksi dalam waktu singkat.\n",
        "###### - **Ukuran Model**: Model harus cukup kecil untuk muat di perangkat target.\n",
        "###### - **Konsumsi Daya**: Model harus hemat energi, terutama untuk perangkat bertenaga baterai.\n",
        "###### - **Kompatibilitas Perangkat Keras**: Model harus kompatibel dengan perangkat target seperti CPU, GPU, atau TPU.\n",
        "###### - **Ketahanan terhadap Latency**: Model harus tetap dapat digunakan pada aplikasi yang membutuhkan inferensi real-time.\n",
        "\n",
        "#### Dalam simulasi ini, kita akan menggunakan teknik pruning, quantization, dan knowledge distillation untuk\n",
        "#### mengoptimalkan model agar memenuhi pertimbangan-pertimbangan ini."
      ],
      "metadata": {
        "id": "rLuQglk82-b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengukur Kecepatan Inferensi\n",
        "import time\n",
        "\n",
        "def measure_inference_time(model, input_tensor):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        _ = model(input_tensor)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time\n",
        "\n",
        "# Simulasi input untuk model\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Mengukur waktu inferensi model asli\n",
        "inference_time_original = measure_inference_time(model, dummy_input)\n",
        "print(f\"\\n[INFO] Waktu inferensi model asli: {inference_time_original:.6f} detik\")\n",
        "\n",
        "# Mengukur Ukuran Model\n",
        "\n",
        "def calculate_model_size(model):\n",
        "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
        "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
        "    size_all_mb = (param_size + buffer_size) / (1024**2)\n",
        "    return size_all_mb\n",
        "\n",
        "model_size = calculate_model_size(model)\n",
        "print(f\"[INFO] Ukuran model asli: {model_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_t6lAmJ9oRO",
        "outputId": "adc51e92-81c0-45ac-a878-7a41842d650b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Waktu inferensi model asli: 0.093330 detik\n",
            "[INFO] Ukuran model asli: 44.63 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Model Optimization Tools and Frameworks\n",
        "### Penjelasan:\n",
        "### Tools yang dapat digunakan untuk optimasi model meliputi:\n",
        "##### - **TensorRT**: Library optimasi model deep learning khusus untuk perangkat NVIDIA.\n",
        "##### - **ONNX Runtime**: Framework lintas platform untuk menjalankan model dengan performa tinggi.\n",
        "##### - **PyTorch Mobile**: Optimasi model PyTorch untuk perangkat mobile.\n",
        "##### - **Core ML**: Framework optimasi untuk perangkat Apple.\n",
        "\n",
        "##### a. Pruning\n",
        "##### Penjelasan:\n",
        "##### Pruning adalah teknik untuk menghapus parameter yang kontribusinya kecil terhadap hasil akhir model.\n",
        "##### Dengan demikian, ukuran model dapat dikurangi tanpa mengorbankan performa secara signifikan."
      ],
      "metadata": {
        "id": "yVqgR60-38I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[INFO] Model sebelum pruning:\")\n",
        "print(model)\n",
        "\n",
        "# Memilih layer untuk pruning\n",
        "parameters_to_prune = (\n",
        "    (model.layer1[0].conv1, 'weight'),\n",
        "    (model.layer1[0].conv2, 'weight'),\n",
        ")\n",
        "\n",
        "# Melakukan pruning (contoh: memangkas 20% bobot)\n",
        "for layer, param in parameters_to_prune:\n",
        "    prune.l1_unstructured(layer, name=param, amount=0.2)\n",
        "\n",
        "print(\"\\n[INFO] Model setelah pruning:\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho-3keYB4QgA",
        "outputId": "cbc0ef1d-1741-4644-f8a9-f45fa2d7f2c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Model sebelum pruning:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "\n",
            "[INFO] Model setelah pruning:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Penjelasan tambahan:\n",
        "##### Setelah pruning, model tetap berfungsi tetapi bobot yang kecil telah dihapus untuk efisiensi.\n",
        "##### Efek ini dapat dievaluasi lebih lanjut menggunakan dataset validasi untuk memastikan tidak ada penurunan akurasi yang signifikan.\n",
        "\n",
        "##### b. Quantization\n",
        "##### Penjelasan:\n",
        "##### Quantization adalah teknik untuk mengurangi precision data dalam model (misalnya dari float32 ke int8).\n",
        "##### Teknik ini mengurangi ukuran model dan mempercepat inferensi tanpa kehilangan performa yang signifikan."
      ],
      "metadata": {
        "id": "ncvSd5ln4UxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model_quantized = torch.quantization.quantize_dynamic(\n",
        "    model,  # Model yang akan di-quantize\n",
        "    {torch.nn.Linear},  # Layer yang akan di-quantize\n",
        "    dtype=torch.qint8,  # Format quantization\n",
        "    inplace=True # Apply quantization directly to the original model\n",
        ")\n",
        "\n",
        "print(\"\\n[INFO] Model setelah quantization:\")\n",
        "print(model_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1cVjRxQ4lwf",
        "outputId": "fbe4d118-bc55-4f2b-ddf5-da2f58579ad1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Model setelah quantization:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): DynamicQuantizedLinear(in_features=512, out_features=1000, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Penjelasan tambahan:\n",
        "##### Model yang sudah di-quantize menggunakan precision yang lebih rendah (int8) sehingga lebih efisien.\n",
        "##### Teknik ini sangat bermanfaat untuk deployment di perangkat dengan sumber daya terbatas.\n",
        "\n",
        "##### c. Knowledge Distillation\n",
        "##### Penjelasan:\n",
        "##### Knowledge distillation adalah proses transfer \"pengetahuan\" dari model besar (teacher) ke model lebih kecil (student).\n",
        "##### Tujuan teknik ini adalah melatih model kecil agar memiliki performa yang mendekati model besar dengan memanfaatkan keluaran model teacher."
      ],
      "metadata": {
        "id": "SnMldvT84pz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = models.resnet50(pretrained=True)\n",
        "student_model = models.resnet18(pretrained=False)\n",
        "\n",
        "# Definisi fungsi loss untuk knowledge distillation\n",
        "def distillation_loss(student_output, teacher_output, ground_truth, alpha=0.5, temperature=2.0):\n",
        "    \"\"\"\n",
        "    Fungsi untuk menghitung distillation loss.\n",
        "    Args:\n",
        "        student_output: Output dari model student.\n",
        "        teacher_output: Output dari model teacher.\n",
        "        ground_truth: Label ground truth.\n",
        "        alpha: Faktor pembobot untuk kombinasi loss.\n",
        "        temperature: Suhu untuk smoothing distribusi probabilitas.\n",
        "    Returns:\n",
        "        Kombinasi loss dari ground truth dan teacher output.\n",
        "    \"\"\"\n",
        "    criterion_ce = torch.nn.CrossEntropyLoss()\n",
        "    criterion_kl = torch.nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    # Loss dari ground truth (Cross Entropy Loss)\n",
        "    ce_loss = criterion_ce(student_output, ground_truth)\n",
        "    # Loss dari teacher output (Kullback-Leibler Divergence)\n",
        "    kl_loss = criterion_kl(\n",
        "        torch.nn.functional.log_softmax(student_output / temperature, dim=1),\n",
        "        torch.nn.functional.softmax(teacher_output / temperature, dim=1)\n",
        "    )\n",
        "\n",
        "    # Kombinasi loss\n",
        "    return alpha * ce_loss + (1 - alpha) * kl_loss\n",
        "\n",
        "# Simulasi keluaran student dan teacher\n",
        "dummy_student_output = torch.randn(8, 1000)\n",
        "dummy_teacher_output = torch.randn(8, 1000)\n",
        "dummy_ground_truth = torch.randint(0, 1000, (8,))\n",
        "\n",
        "# Hitung distillation loss\n",
        "loss = distillation_loss(dummy_student_output, dummy_teacher_output, dummy_ground_truth)\n",
        "print(\"\\n[INFO] Distillation Loss:\", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk_Eh6_54wZc",
        "outputId": "c4e47355-da61-46e5-bd09-5a0a117d5a12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Distillation Loss: 3.584193468093872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Penjelasan tambahan:\n",
        "##### Dengan knowledge distillation, model student dapat belajar tidak hanya dari ground truth,\n",
        "##### tetapi juga dari keluaran model teacher yang mengandung informasi tambahan.\n",
        "\n",
        "## Kesimpulan:\n",
        "###### Unit 9 mencakup tiga teknik utama untuk optimasi model:\n",
        "###### 1. Pruning untuk menghapus parameter yang kurang penting.\n",
        "###### 2. Quantization untuk mengurangi precision data dan meningkatkan efisiensi.\n",
        "###### 3. Knowledge distillation untuk mentransfer pengetahuan dari model besar ke model kecil.\n",
        "\n",
        "#### Teknik-teknik ini membantu membuat model lebih ringan, cepat, dan efisien untuk deployment."
      ],
      "metadata": {
        "id": "kq1WhQ9a5IhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 10: Synthetic Data Generation\n",
        "\n",
        "### 1. Introduction\n",
        "#### Penjelasan:\n",
        "##### Data sintetis adalah data yang dihasilkan menggunakan algoritma komputer, bukan data nyata yang diambil dari dunia fisik.\n",
        "##### Data ini sangat berguna dalam pengembangan model pembelajaran mesin, terutama ketika:\n",
        "##### - Data nyata sulit didapat atau mahal untuk dikumpulkan.\n",
        "##### - Variasi yang lebih luas dari data diperlukan untuk melatih model yang lebih robust.\n",
        "##### - Perlindungan privasi menjadi perhatian utama, seperti dalam data medis.\n",
        "##### - Meningkatkan generalisasi model dengan menghadirkan kondisi ekstrem atau skenario yang jarang terjadi."
      ],
      "metadata": {
        "id": "ppCgW_Z9ATbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Introduction to Synthetic Data Generation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i-tx68iAS3b",
        "outputId": "159dbc59-f706-4290-9674-f133cd2044ca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Introduction to Synthetic Data Generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Synthetic Datasets\n",
        "#### Contoh dataset sintetis yang sering digunakan:\n",
        "##### - **CARLA**: Dataset untuk pelatihan model self-driving yang mensimulasikan lingkungan perkotaan dengan kendaraan dan pejalan kaki.\n",
        "##### - **SimCLR**: Framework pembelajaran representasi self-supervised dengan augmentasi data sintetis.\n",
        "##### - **BlenderProc**: Sebuah alat untuk membuat dataset 3D dengan memanfaatkan kemampuan rendering Blender.\n",
        "\n",
        "#### Dataset sintetis ini digunakan untuk melatih model dengan skenario yang sulit dilakukan pada data dunia nyata,\n",
        "#### seperti data tabrakan mobil atau kondisi cuaca ekstrem.\n"
      ],
      "metadata": {
        "id": "Uh6alOfzBfKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Examples of Synthetic Datasets:\")\n",
        "synthetic_datasets = [\"CARLA\", \"SimCLR\", \"BlenderProc\"]\n",
        "for dataset in synthetic_datasets:\n",
        "    print(f\"- {dataset}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "extto_8gCFv8",
        "outputId": "9a7f7b6b-de47-4597-b678-50245d483693"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Examples of Synthetic Datasets:\n",
            "- CARLA\n",
            "- SimCLR\n",
            "- BlenderProc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Using a 3D Renderer to Generate Synthetic Data\n",
        "#### Penjelasan:\n",
        "#### Renderer 3D seperti Blender atau Unity memungkinkan kita untuk membuat data dengan variasi yang luas\n",
        "#### (seperti sudut pandang kamera, pencahayaan, atau tekstur objek). Data yang dihasilkan dapat berupa gambar, video, atau bahkan point clouds.\n",
        "#### Alat ini sangat bermanfaat untuk melatih model dalam skenario seperti robotika, augmented reality, dan autonomous driving.\n"
      ],
      "metadata": {
        "id": "jSe_g5QeCHf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulasi kode (dalam skenario nyata, ini akan diimplementasikan di Blender atau alat sejenis)\n",
        "def generate_synthetic_data_with_renderer(renderer, object_count=10):\n",
        "    print(f\"[INFO] Generating synthetic data using {renderer}...\")\n",
        "    for i in range(object_count):\n",
        "        print(f\"Generating object {i + 1}...\")\n",
        "\n",
        "# Menggunakan fungsi untuk simulasi pembuatan data\n",
        "renderer_name = \"Blender\"\n",
        "generate_synthetic_data_with_renderer(renderer_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBfMtRlQCPdB",
        "outputId": "92a0afbd-38d8-4878-fe19-2e379ed0fa43"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Generating synthetic data using Blender...\n",
            "Generating object 1...\n",
            "Generating object 2...\n",
            "Generating object 3...\n",
            "Generating object 4...\n",
            "Generating object 5...\n",
            "Generating object 6...\n",
            "Generating object 7...\n",
            "Generating object 8...\n",
            "Generating object 9...\n",
            "Generating object 10...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Synthetic Data Generation Using DCGAN\n",
        "#### Penjelasan:\n",
        "#### DCGAN (Deep Convolutional Generative Adversarial Network) adalah jenis GAN yang sering digunakan\n",
        "#### untuk menghasilkan gambar sintetis. GAN terdiri dari dua jaringan: generator dan discriminator.\n",
        "#### Generator bertugas menghasilkan data palsu, sedangkan discriminator bertugas membedakan data palsu dan data asli.\n",
        "#### Dengan pelatihan bersamaan, generator belajar untuk menghasilkan data yang semakin realistis.\n"
      ],
      "metadata": {
        "id": "s83IDkQRCVet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Generator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 64, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "L0NDdqEXCcBJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Penjelasan tambahan:\n",
        "#### Model generator menghasilkan gambar sintetis dari noise acak, sedangkan discriminator mengevaluasi keaslian gambar tersebut."
      ],
      "metadata": {
        "id": "qw_BvuN2Ci_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Synthetic Data Generation with Diffusion Models\n",
        "#### Penjelasan:\n",
        "#### Diffusion Models adalah model generatif terbaru yang digunakan untuk menghasilkan data yang realistis.\n",
        "#### Model ini bekerja dengan menyaring noise secara bertahap hingga menghasilkan gambar akhir.\n",
        "#### Proses ini menyerupai pembalikan proses difusi, di mana data diubah menjadi noise selama pelatihan.\n"
      ],
      "metadata": {
        "id": "6G4RC_a6Cpki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Diffusion Models will be implemented in the next step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unrMY5WHCwTj",
        "outputId": "5cba4008-4096-4041-ca57-bda9ba12ec57"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Diffusion Models will be implemented in the next step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Challenges and Opportunities Associated With Using Synthetic Data\n",
        "#### Penjelasan:\n",
        "#### - Tantangan: Domain gap antara data sintetis dan data nyata yang dapat memengaruhi performa model di dunia nyata.\n",
        "####   - Domain gap dapat diatasi dengan domain adaptation atau training joint dengan data nyata dan sintetis.\n",
        "#### - Peluang: Data sintetis memungkinkan eksplorasi skenario langka yang sulit dilakukan dengan data nyata,\n",
        "####   seperti kondisi cuaca ekstrem, bencana alam, atau simulasi situasi berbahaya."
      ],
      "metadata": {
        "id": "V0CnZmP_Cw87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Challenges and opportunities with synthetic data discussed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiIYGuoiC3st",
        "outputId": "5cbb22d2-e457-4962-817a-b294c9818924"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Challenges and opportunities with synthetic data discussed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Introduction to Point Clouds\n",
        "#### Penjelasan:\n",
        "#### Point clouds adalah kumpulan titik 3D yang mewakili bentuk atau permukaan suatu objek.\n",
        "#### Data ini sering digunakan dalam aplikasi seperti pemetaan 3D, pengenalan objek, dan autonomous driving.\n",
        "#### Point clouds biasanya dihasilkan oleh sensor LiDAR atau kamera depth."
      ],
      "metadata": {
        "id": "vY-VQtpWC5ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Introduction to Point Clouds:\")\n",
        "print(\"Point clouds are used in 3D vision tasks, including LiDAR data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AeDA_tTC_gJ",
        "outputId": "49f4b7c8-7049-4c02-8918-2b5fd6dd4942"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Introduction to Point Clouds:\n",
            "Point clouds are used in 3D vision tasks, including LiDAR data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 11: Zero-Shot Learning\n",
        "\n",
        "### 1. Introduction\n",
        "#### Penjelasan:\n",
        "#### Zero-Shot Learning (ZSL) adalah pendekatan dalam pembelajaran mesin di mana model dapat mengenali kelas objek\n",
        "#### yang belum pernah dilihat selama pelatihan. Teknik ini memanfaatkan informasi tambahan seperti deskripsi tekstual,\n",
        "#### atribut, atau fitur lain untuk menghubungkan kelas yang terlihat dan yang tidak terlihat.\n",
        "#### ZSL memanfaatkan kekuatan representasi umum, memungkinkan model untuk belajar dengan cara generalisasi yang lebih luas.\n",
        "#### Dengan kata lain, model belajar memahami konsep-konsep mendasar sehingga mampu mengenali hal-hal baru hanya\n",
        "#### berdasarkan deskripsi atau atributnya.\n",
        "\n",
        "#### Keunggulan ZSL:\n",
        "##### - Mengurangi kebutuhan anotasi data yang mahal.\n",
        "##### - Meningkatkan fleksibilitas model untuk menangani kategori baru.\n",
        "##### - Berguna dalam skenario di mana data kelas tertentu sulit atau tidak mungkin diperoleh.\n",
        "\n",
        "#### Contoh aplikasi Zero-Shot Learning:\n",
        "##### - **Visi Komputer**: Pengenalan objek baru yang tidak ada dalam dataset pelatihan.\n",
        "##### - **Pemrosesan Bahasa Alami**: Klasifikasi teks atau entitas tanpa pelatihan khusus pada kelas target.\n",
        "##### - **Sistem Rekomendasi**: Mampu merekomendasikan produk atau layanan baru yang belum pernah dilihat sebelumnya.\n",
        "##### - **Robotika**: Memahami perintah baru tanpa pelatihan tambahan."
      ],
      "metadata": {
        "id": "dcBRbQO5D3Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Introduction to Zero-Shot Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVvipth6Fi4L",
        "outputId": "bb3e1ffb-2fa7-41f7-9acb-85c739825150"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Introduction to Zero-Shot Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Zero-Shot Learning\n",
        "#### Penjelasan:\n",
        "#### Dalam Zero-Shot Learning, ada dua pendekatan utama yang sering digunakan:\n",
        "##### - **Embedding-Based Methods**: Pada pendekatan ini, baik gambar maupun deskripsi kelas dipetakan ke ruang vektor yang sama.\n",
        "#####   Kesamaan antara vektor digunakan untuk memprediksi kelas. Model seperti CLIP menggunakan metode ini.\n",
        "##### - **Generative-Based Methods**: Pendekatan ini menggunakan model generatif seperti GAN atau Diffusion Models untuk\n",
        "#####   mensintesis fitur visual untuk kelas yang tidak terlihat. Fitur ini kemudian digunakan untuk melatih model klasifikasi tambahan.\n",
        "\n",
        "#### Implementasi Zero-Shot Learning menggunakan model CLIP:\n",
        "#### CLIP (Contrastive Language–Image Pre-training) adalah model dari OpenAI yang menghubungkan teks dan gambar.\n",
        "#### Model ini mempelajari representasi bersama untuk teks dan gambar, sehingga memungkinkan Zero-Shot Learning."
      ],
      "metadata": {
        "id": "aHg_1z5eFk0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "\n",
        "# Memuat model CLIP\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Contoh gambar dan teks untuk prediksi Zero-Shot\n",
        "image_path = \"/content/kuching.jpg\"  # Ganti dengan path ke gambar Anda\n",
        "texts = [\"Kucing\", \"Anjing\", \"Sepeda\"]  # Label teks yang ingin diuji\n",
        "\n",
        "# Memproses gambar dan teks\n",
        "from PIL import Image\n",
        "image = Image.open(image_path)\n",
        "inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Melakukan prediksi\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image  # Skor prediksi\n",
        "probs = logits_per_image.softmax(dim=1)  # Probabilitas untuk setiap label teks\n",
        "\n",
        "# Menampilkan hasil\n",
        "for i, text in enumerate(texts):\n",
        "    print(f\"Label: {text}, Probabilitas: {probs[0][i].item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fOqobilF2ej",
        "outputId": "49cdbe91-edf3-42f0-cbf1-02e98b210881"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: Kucing, Probabilitas: 0.9675\n",
            "Label: Anjing, Probabilitas: 0.0324\n",
            "Label: Sepeda, Probabilitas: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Penjelasan tambahan:\n",
        "##### - CLIP memanfaatkan representasi bersama untuk teks dan gambar, sehingga model dapat melakukan prediksi\n",
        "#####   untuk kelas baru tanpa data pelatihan tambahan.\n",
        "##### - Model CLIP dilatih pada dataset besar yang mencakup berbagai pasangan teks-gambar, sehingga\n",
        "#####   dapat memahami konsep yang luas.\n",
        "##### - Dengan memberikan deskripsi teks yang tepat, model dapat mengenali gambar yang belum pernah dilihat sebelumnya.\n",
        "#####   Misalnya, jika gambar adalah \"sepeda\", dan teks menjelaskan \"kendaraan roda dua dengan pedal\", model dapat\n",
        "#####   menghubungkan deskripsi tersebut dengan gambar.\n",
        "\n",
        "## Kesimpulan:\n",
        "#### Zero-Shot Learning membuka peluang baru untuk menerapkan pembelajaran mesin dalam skenario dengan keterbatasan data,\n",
        "#### sekaligus memungkinkan model untuk lebih fleksibel dalam menangani kelas yang baru atau tidak terlihat.\n",
        "#### Pendekatan ini sangat bermanfaat dalam aplikasi dunia nyata di mana ketersediaan data sering menjadi tantangan utama."
      ],
      "metadata": {
        "id": "YYBRb2IGF5Hh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 12: Ethics and Bias in Computer Vision\n",
        "\n",
        "### 1. Exploring Ethical Foundations in CV Models\n",
        "#### Penjelasan:\n",
        "#### Dalam pengembangan model visi komputer (CV), pertimbangan etika sangat penting untuk memastikan teknologi digunakan\n",
        "#### secara bertanggung jawab. Teknologi CV memiliki potensi besar untuk memberikan manfaat, seperti dalam bidang medis,\n",
        "#### keamanan, dan transportasi. Namun, jika tidak dikembangkan dengan benar, teknologi ini dapat memperkuat bias yang ada,\n",
        "#### melanggar privasi, atau menyebabkan kerugian lain bagi individu atau kelompok tertentu.\n",
        "\n",
        "#### Beberapa pertimbangan etis utama:\n",
        "##### - **Privasi**: Apakah data yang digunakan melanggar privasi seseorang? Contohnya adalah sistem pengenalan wajah\n",
        "#####   yang menangkap data visual tanpa persetujuan pengguna.\n",
        "##### - **Bias**: Apakah model memperlakukan kelompok tertentu secara tidak adil? Misalnya, algoritma yang lebih akurat\n",
        "#####   dalam mengenali wajah orang dari ras tertentu dibandingkan ras lainnya.\n",
        "##### - **Keamanan**: Apakah model aman dari penyalahgunaan atau serangan adversarial? Misalnya, gambar yang dimodifikasi\n",
        "#####   untuk mengecoh model pengenalan objek sehingga memberikan hasil yang salah.\n",
        "\n",
        "#### Dengan memahami dasar-dasar etika dalam model CV, pengembang dapat mengambil langkah untuk meminimalkan risiko\n",
        "#### yang mungkin terjadi akibat penggunaan teknologi ini."
      ],
      "metadata": {
        "id": "-ta1bqxJIXW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Exploring Ethical Foundations in CV Models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqyTTXx9Ivbh",
        "outputId": "a042da52-03e6-4f5e-8e82-178231e3c191"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Exploring Ethical Foundations in CV Models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Introduction\n",
        "#### Penjelasan:\n",
        "#### Etika dalam AI dan visi komputer mencakup banyak aspek, mulai dari pengumpulan data hingga penerapan model.\n",
        "#### Penggunaan dataset yang bias atau desain model yang tidak hati-hati dapat menyebabkan keputusan yang tidak adil.\n",
        "#### Oleh karena itu, pengembang harus mempertimbangkan dampak sosial dan etika dari teknologi yang mereka kembangkan.\n",
        "\n",
        "#### Contoh kasus:\n",
        "##### - Sistem pengenalan wajah yang lebih akurat untuk kelompok tertentu, tetapi gagal untuk kelompok lain.\n",
        "##### - Algoritma deteksi objek yang gagal mengenali variasi budaya dalam pakaian atau barang.\n",
        "##### - Sistem keamanan berbasis CV yang secara tidak adil menargetkan kelompok tertentu karena bias data pelatihan.\n",
        "\n",
        "#### Tujuan utama adalah memastikan bahwa model yang dikembangkan bersifat inklusif, adil, dan tidak merugikan\n",
        "#### kelompok mana pun."
      ],
      "metadata": {
        "id": "JPehgUppI0Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Introduction to Ethics in Computer Vision\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeqUj2JRJD_V",
        "outputId": "1c6be0bd-bd3c-40b2-ac75-f33e584fcd6d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Introduction to Ethics in Computer Vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Ethics and Bias in AI\n",
        "#### Penjelasan:\n",
        "#### Bias dalam AI dapat berasal dari berbagai sumber, termasuk dataset, algoritma, dan interpretasi hasil.\n",
        "#### Bias dataset adalah salah satu penyebab paling umum, di mana data pelatihan tidak mencakup variasi yang cukup\n",
        "#### untuk mewakili semua kelompok atau kondisi. Sebagai contoh, jika dataset hanya berisi gambar dari lingkungan\n",
        "#### perkotaan, model mungkin tidak dapat mengenali objek dalam lingkungan pedesaan.\n",
        "\n",
        "#### Jenis-jenis bias dalam AI:\n",
        "##### - **Bias Dataset**: Ketidakseimbangan dalam distribusi data berdasarkan atribut seperti gender, ras, atau usia.\n",
        "##### - **Bias Algoritmik**: Algoritma yang dirancang tanpa mempertimbangkan keragaman data, sehingga menghasilkan model yang tidak adil.\n",
        "##### - **Bias Interpretasi**: Kesalahan dalam memahami hasil model, seringkali disebabkan oleh prasangka manusia."
      ],
      "metadata": {
        "id": "F7QhanAcJIWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh kode sederhana untuk mendeteksi bias dalam dataset:\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_bias(dataset_path, column):\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    print(f\"Distribusi nilai pada kolom {column}:\")\n",
        "    print(data[column].value_counts(normalize=True))\n",
        "\n",
        "# Penggunaan fungsi ini:\n",
        "# analyze_bias(\"dataset.csv\", \"gender\")"
      ],
      "metadata": {
        "id": "gQ3xz8bhJWJA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Penjelasan tambahan:\n",
        "#### Fungsi ini membantu mengidentifikasi distribusi data pada atribut tertentu. Ketidakseimbangan yang signifikan\n",
        "#### dalam distribusi ini dapat menunjukkan adanya bias dataset yang perlu diperbaiki."
      ],
      "metadata": {
        "id": "vNyfV4u7J62p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Ethics and Bias in AI discussed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auqFO6trKGBN",
        "outputId": "7123e266-82b8-467e-9f31-4d361362ee84"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Ethics and Bias in AI discussed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Hugging Face's Efforts: Ethics and Society\n",
        "#### Penjelasan:\n",
        "#### Hugging Face berkomitmen untuk memastikan pengembangan AI yang etis. Mereka memiliki tim yang fokus pada\n",
        "#### dampak sosial dan etika dari teknologi AI. Tim ini bekerja untuk mengidentifikasi potensi risiko dan\n",
        "#### menyusun pedoman untuk meminimalkan bias dalam model AI.\n",
        "\n",
        "#### Beberapa inisiatif Hugging Face:\n",
        "##### - **Transparansi Model**: Memberikan dokumentasi yang jelas tentang bagaimana model dilatih dan dataset apa yang digunakan.\n",
        "##### - **Panduan Etika**: Menyediakan panduan tentang cara menggunakan teknologi AI secara bertanggung jawab.\n",
        "##### - **Open Source**: Mendorong keterbukaan dalam pengembangan AI melalui repositori open source, sehingga\n",
        "####   pengembang lain dapat mengevaluasi dan meningkatkan teknologi tersebut."
      ],
      "metadata": {
        "id": "Q0JKqCVbKGyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Hugging Face's Efforts in Ethics and Society\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJzMOTatKSLz",
        "outputId": "c2994d35-0ba2-4121-d321-a91c7884a1d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Hugging Face's Efforts in Ethics and Society\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Supplementary Reading and Resources\n",
        "#### Penjelasan:\n",
        "#### Untuk memperdalam pemahaman tentang etika dalam AI dan visi komputer, tersedia banyak sumber daya tambahan.\n",
        "#### Berikut adalah beberapa rekomendasi:\n",
        "##### - **Kursus fast.ai tentang Etika AI**: Kursus ini membahas berbagai aspek etika dalam pengembangan AI,termasuk dampak sosial dari teknologi ini.\n",
        "##### - **Buku \"Artificial Unintelligence\"**: Buku ini mengeksplorasi bagaimana bias dan kesalahan desain dapat  memengaruhi AI serta memberikan wawasan tentang cara mengatasi masalah tersebut.\n",
        "##### - **Laporan Montreal AI Ethics Institute**: Laporan ini mencakup tren terbaru, tantangan, dan peluang dalam etika AI, serta memberikan rekomendasi untuk pengembang dan pembuat kebijakan.\n",
        "\n",
        "## Penjelasan tambahan:\n",
        "#### Dengan membaca sumber-sumber ini, pengembang dapat memperoleh wawasan mendalam tentang bagaimana membuat\n",
        "#### teknologi AI yang lebih adil dan inklusif."
      ],
      "metadata": {
        "id": "qU-OCyskKT3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Supplementary Reading and Resources Provided\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8vdPkXKKh8F",
        "outputId": "55988f31-b01c-4ba5-f83d-bb16e319ab1d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Supplementary Reading and Resources Provided\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kesimpulan:\n",
        "#### Etika dan bias dalam visi komputer adalah topik penting yang memerlukan perhatian serius dari pengembang.\n",
        "#### Dengan memahami dan mengatasi bias, kita dapat memastikan bahwa teknologi AI digunakan untuk kebaikan bersama,\n",
        "#### tanpa menyebabkan kerugian atau ketidakadilan. Pendekatan ini membutuhkan kolaborasi antara pengembang,\n",
        "#### peneliti, pembuat kebijakan, dan masyarakat luas untuk menciptakan ekosistem AI yang lebih adil dan bertanggung jawab."
      ],
      "metadata": {
        "id": "7086lj5-KkMo"
      }
    }
  ]
}